{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab: Building Advanced Transformers**\n",
    "\n",
    "**Estimated time needed:  30 minutes**  \n",
    "\n",
    "In this lab, you will implement and experiment with advanced Transformer models using Keras. \n",
    "\n",
    "**Learning objectives:** \n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "- Understand the core components of a Transformer architecture.\n",
    "- Implement a multi-head self-attention mechanism from scratch.\n",
    "- Train and evaluate a Transformer for time series prediction.\n",
    "- Handle preprocessing and scaling for time series data effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Transformer?\n",
    "\n",
    "The Transformer architecture was introduced in the paper *\"Attention Is All You Need\"*. It revolutionized natural language processing by using attention mechanisms instead of recurrence.\n",
    "\n",
    "### Key Components:\n",
    "- **Input Embedding:** Converts input tokens (or time steps) into vectors.\n",
    "- **Positional Encoding:** Injects information about the position of input tokens.\n",
    "- **Multi-Head Self-Attention:** Allows the model to focus on different parts of the input sequence.\n",
    "- **Feedforward Layers:** Process the attended information.\n",
    "- **Layer Normalization & Residual Connections:** Stabilize and speed up training.\n",
    "\n",
    "> Transformers are now widely used not only in NLP but also in time series forecasting, image recognition, and more.\n",
    "\n",
    "**Next:** You will implement parts of this architecture step-by-step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-Step Instructions: \n",
    "\n",
    "### Step 1: Import necessary libraries \n",
    "\n",
    "Before you start, you need to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.75.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting numpy>=1.26.0 (from tensorflow)\n",
      "  Downloading numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.15.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow)\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pillow (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.75.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.15.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
      "Downloading markdown-3.9-py3-none-any.whl (107 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (408 kB)\n",
      "Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorboard-data-server, pyarrow, protobuf, pillow, optree, opt_einsum, numpy, mdurl, markdown, grpcio, google_pasta, gast, astunparse, absl-py, tensorboard, ml_dtypes, markdown-it-py, h5py, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.9.23 gast-0.6.0 google_pasta-0.2.0 grpcio-1.75.1 h5py-3.15.0 keras-3.11.3 libclang-18.1.1 markdown-3.9 markdown-it-py-4.0.0 mdurl-0.1.2 ml_dtypes-0.5.3 namex-0.1.0 numpy-2.3.3 opt_einsum-3.4.0 optree-0.17.0 pillow-11.3.0 protobuf-6.32.1 pyarrow-21.0.0 rich-14.2.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.1.0 werkzeug-3.1.3 wrapt-1.17.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m155.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.3.3 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (2.3.3)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m112.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading scipy-1.16.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.16.2 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.60.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (112 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.60.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.60.1 kiwisolver-1.4.9 matplotlib-3.10.7 pyparsing-3.2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow pyarrow \n",
    "%pip install pandas  \n",
    "%pip install scikit-learn \n",
    "%pip install matplotlib \n",
    "%pip install requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Setup the Environment to generate synthetic stock price data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic stock_prices.csv created and loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a synthetic stock price dataset\n",
    "np.random.seed(42)\n",
    "data_length = 2000  # Adjust data length as needed\n",
    "trend = np.linspace(100, 200, data_length)\n",
    "noise = np.random.normal(0, 2, data_length)\n",
    "synthetic_data = trend + noise\n",
    "\n",
    "# Create a DataFrame and save as 'stock_prices.csv'\n",
    "data = pd.DataFrame(synthetic_data, columns=['Close'])\n",
    "data.to_csv('stock_prices.csv', index=False)\n",
    "print(\"Synthetic stock_prices.csv created and loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1899, 100, 1)\n",
      "Shape of Y: (1899,)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset \n",
    "data = pd.read_csv('stock_prices.csv') \n",
    "data = data[['Close']].values \n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Prepare the data for training\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        a = data[i:(i+time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "time_step = 100\n",
    "X, Y = create_dataset(data, time_step)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "print(\"Shape of X:\", X.shape) \n",
    "print(\"Shape of Y:\", Y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "`tensorflow` is the main library for machine learning in Python.  \n",
    "\n",
    "`stock_prices.csv` is the data set that is loaded. \n",
    "\n",
    "`MinMaxScaler` method is used to normalize the data.  \n",
    "\n",
    "`create_dataset`method is used to prepare the data for training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Multi-Head Self-Attention \n",
    "\n",
    "Define the Multi-Head Self-Attention mechanism. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    "\n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The MultiHeadSelfAttention layer implements the multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence simultaneously. \n",
    "\n",
    "- The attention parameter computes the attention scores and weighted sum of the values. \n",
    "\n",
    "- The split_heads parameter splits the input into multiple heads for parallel attention computation. \n",
    "\n",
    "- The call method applies the self-attention mechanism and combines the heads. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement Transformer block \n",
    "\n",
    "Define the Transformer block. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code:\n",
    "\n",
    "- The TransformerBlock layer combines multi-head self-attention with a feed-forward neural network and normalization layers.  \n",
    "\n",
    "- Dropout is used to prevent overfitting. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Implement Encoder Layer \n",
    "\n",
    "Define the Encoder layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(EncoderLayer, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The EncoderLayer is similar to the TransformerBlock but is a reusable layer in the Transformer architecture. \n",
    "\n",
    "- It consists of a MultiHeadSelfAttention mechanism followed by a feedforward neural network. \n",
    "\n",
    "- Both sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network, with residual connections and layer normalization. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Implement Transformer encoder \n",
    "\n",
    "Define the Transformer Encoder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 00:05:17.996036: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout \n",
    "\n",
    "class MultiHeadSelfAttention(Layer): \n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    " \n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    "class TransformerBlock(Layer): \n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n",
    "class TransformerEncoder(Layer): \n",
    "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerEncoder, self).__init__() \n",
    "        self.num_layers = num_layers \n",
    "        self.embed_dim = embed_dim \n",
    "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)] \n",
    "        self.dropout = Dropout(rate) \n",
    "\n",
    "    def call(self, inputs, training=False): \n",
    "        x = inputs \n",
    "        for i in range(self.num_layers): \n",
    "            x = self.enc_layers[i](x, training=training) \n",
    "        return x \n",
    "\n",
    "# Example usage \n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "inputs = tf.random.uniform((1, 100, embed_dim)) \n",
    "outputs = transformer_encoder(inputs, training=False)  # Use keyword argument for 'training' \n",
    "print(outputs.shape)  # Should print (1, 100, 128) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Build and Compile the Transformer model \n",
    "\n",
    "Integrate the Transformer Encoder into a complete model for sequential data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the necessary parameters \n",
    "\n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "# Define the Transformer Encoder \n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "\n",
    "# Build the model \n",
    "input_shape = (X.shape[1], X.shape[2]) \n",
    "inputs = tf.keras.Input(shape=input_shape) \n",
    "\n",
    "# Project the inputs to the embed_dim \n",
    "x = tf.keras.layers.Dense(embed_dim)(inputs) \n",
    "encoder_outputs = transformer_encoder(x) \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "outputs = tf.keras.layers.Dense(1)(flatten) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The Transformer Encoder model defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output.  \n",
    "\n",
    "- The model is then compiled with the Adam optimizer and mean squared error loss. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train the Transformer model \n",
    "\n",
    "Train the model on the prepared dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 1s/step - loss: 3.7242  \n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.2072 \n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.1664 \n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.1574 \n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.1334 \n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.1336 \n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.1487 \n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.1466 \n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.1159 \n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.1327 \n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.1052 \n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.1331 \n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0991 \n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0843 \n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0761 \n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0665 \n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0468 \n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - loss: 0.0650 \n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0438 \n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0351 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7638ded5ae70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The model is trained on the normalized stock price data for 20 epochs with a batch size of 32. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate and Make Predictions \n",
    "\n",
    "Evaluate the model's performance and make predictions on the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 324ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions \n",
    "predictions = model.predict(X) \n",
    "predictions = scaler.inverse_transform(predictions) \n",
    "\n",
    "# Prepare true values for comparison\n",
    "true_values = scaler.inverse_transform(data.reshape(-1, 1))\n",
    "\n",
    "# Plot the predictions vs true values\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(true_values, label='True Data') \n",
    "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions') \n",
    "plt.xlabel('Time') \n",
    "plt.ylabel('Stock Price') \n",
    "plt.legend() \n",
    "plt.title('Predictions vs True Data (Both Scaled Back)')\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The model's predictions are transformed back to the original scale using the inverse transform of the scaler. \n",
    "\n",
    "- The true data and predictions are plotted to visualize the model's performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises: \n",
    "\n",
    " ### Exercise 1: Add dropout to the Transformer model \n",
    "\n",
    " **Objective: Understand how to add dropout layers to the Transformer model to prevent overfitting.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Add a dropout layer after the Flatten layer in the model. \n",
    "\n",
    "- Set the dropout rate to 0.5. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 1s/step - loss: 3.4172  \n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 1.1278 \n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.7577 \n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.3873 \n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.1655 \n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.0910 \n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0694 \n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0476 \n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0327 \n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0256 \n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.0235 \n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0193 \n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0179 \n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0226 \n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.0159 \n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0142 \n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0163 \n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0157 \n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.0146 \n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.0134 \n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 317ms/step - loss: 0.0026    \n",
      "Test loss: 0.0025723318103700876\n"
     ]
    }
   ],
   "source": [
    "## Write your code here.\n",
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "  \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "  \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') \n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Experiment with different batch sizes \n",
    "\n",
    "**Objective: Observe the impact of different batch sizes on model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Train the model with a batch size of 16. \n",
    "\n",
    "- Train the model with a batch size of 64. \n",
    "\n",
    "- Compare the training time and performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 633ms/step - loss: 0.0218 \n",
      "Epoch 2/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 629ms/step - loss: 0.0230 \n",
      "Epoch 3/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 630ms/step - loss: 0.0210 \n",
      "Epoch 4/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 621ms/step - loss: 0.0223 \n",
      "Epoch 5/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 627ms/step - loss: 0.0178 \n",
      "Epoch 6/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 629ms/step - loss: 0.0466 \n",
      "Epoch 7/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 631ms/step - loss: 0.0467 \n",
      "Epoch 8/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 624ms/step - loss: 0.0203 \n",
      "Epoch 9/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 627ms/step - loss: 0.0143 \n",
      "Epoch 10/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 629ms/step - loss: 0.0198 \n",
      "Epoch 11/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 629ms/step - loss: 0.0164 \n",
      "Epoch 12/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 629ms/step - loss: 0.0141 \n",
      "Epoch 13/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 630ms/step - loss: 0.0196 \n",
      "Epoch 14/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 630ms/step - loss: 0.0142 \n",
      "Epoch 15/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 630ms/step - loss: 0.0146 \n",
      "Epoch 16/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 636ms/step - loss: 0.0115 \n",
      "Epoch 17/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 632ms/step - loss: 0.0138 \n",
      "Epoch 18/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 629ms/step - loss: 0.0132 \n",
      "Epoch 19/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 637ms/step - loss: 0.0148 \n",
      "Epoch 20/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 630ms/step - loss: 0.0100 \n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 316ms/step - loss: 0.0104\n",
      "Test loss with batch size 16: 0.0103584760800004\n",
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - loss: 0.0072 \n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - loss: 0.0044\n",
      "Epoch 3/20\n",
      "\u001b[1m 8/30\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 2s/step - loss: 0.0034"
     ]
    }
   ],
   "source": [
    "## Write your code here.\n",
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Use a different activation function \n",
    "\n",
    " **Objective: Understand how different activation functions impact the model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Change the activation function of the Dense layer to `tanh`. \n",
    "\n",
    "- Train and evaluate the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here.\n",
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Congratulations on completing this lab! In this lab, you have built an advanced Transformer model using Keras and applied it to a time series forecasting task. You have learned how to define and implement multi-head self-attention, Transformer blocks, encoder layers, and integrate them into a complete Transformer model. By experimenting with different configurations and training the model, you can further improve its performance and apply it to various sequential data tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "8aae4de69f29de06e63c5f2d04ef24811d42d1553c8ac316f7ad75d55f2c2d79"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
